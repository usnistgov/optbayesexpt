
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Manual &#8212; OptBayesExpt 1.1.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/nature.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Demos" href="manual_demos.html" />
    <link rel="prev" title="Quick Start" href="quickstart.html" />

    <link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css" type="text/css" />
    <script src="https://code.jquery.com/jquery-1.12.4.min.js" type="text/javascript"></script>
    <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>

<script type="text/javascript" src="https://pages.nist.gov/leaveNotice/js/jquery.leaveNotice-nist.min.js"></script>
<script>
$(document).ready(function(){
  // Mark external (non-nist.gov) A tags with class "external"
  //If the adress start with https and ends with nist.gov
  var re_nist = new RegExp('^https?:\/\/((^\/)*\.)*nist\\.gov(\/|$)');
  //Regex to find address that start with https
  var re_absolute_address = new RegExp('^((https?:)?\/\/)');
  $("a").each(function(){
    var url=$(this).attr('href');
    if(re_nist.test(url) || !re_absolute_address.test(url)){
      $(this).addClass('local');
    }else{
      //This a href appears to be external, so tag it
      $(this).addClass('external');
    }
  });
  // Add leaveNotice to external A elements
  $('a.external').leaveNotice();
});
</script>
<link rel="stylesheet" type="text/css" href="https://pages.nist.gov/leaveNotice/css/jquery.leaveNotice.css" />

<script async type="text/javascript" id="_fed_an_ua_tag" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=NIST&subagency=github&pua=UA-42404149-54&yt=true&exts=ppsx,pps,f90,sch,rtf,wrl,txz,m1v,xlsm,msi,xsd,f,tif,eps,mpg,xml,pl,xlt,c">
</script>

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="manual_demos.html" title="Demos"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="quickstart.html" title="Quick Start"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">OptBayesExpt 1.1.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Manual</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="manual">
<h1>Manual<a class="headerlink" href="#manual" title="Permalink to this headline">¶</a></h1>
<div class="line-block">
<div class="line">R. D. McMichael <a class="reference external" href="mailto:rmcmichael&#37;&#52;&#48;nist&#46;gov">rmcmichael<span>&#64;</span>nist<span>&#46;</span>gov</a></div>
<div class="line">National Institute of Standards and Technology</div>
<div class="line">Gaithersburg, MD USA</div>
<div class="line">April 7, 2020</div>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>This manual describes an implementation of optimal Bayesian experimental
design methods to control measurement settings in order to efficiently
determine model parameters. In situations where parametric models would
conventionally be fit to measurement data in order to obtain model
parameters, these methods offer an adaptive measurement strategy capable
of reduced uncertainty with fewer required measurements. These methods
are therefore most beneficial in situations where measurements are
expensive in terms of money, time, risk, labor or other cost. The price
for these benefits lies in the complexity of automating such
measurements and in the computational load required. It is the goal of
this package to assist potential users in overcoming at least the
programming hurdles.</p>
<p>Optimal Bayesian experimental design is not new, at least not in the
statistics community. A review paper from 1995 by <a class="reference external" href="https://projecteuclid.org/euclid.ss/1177009939">Kathryn Chaloner and
Isabella Verinelli</a>
reveals that the basic methods had been worked out in preceding decades.
The methods implemented here closely follow <a class="reference external" href="http://dx.doi.org/10.1016/j.jcp.2012.08.013">Xun Huan and Youssef M.
Marzouk</a> which
emphasizes simulation-based experimental design. Optimal Bayesian
experimental design is also an active area of research.</p>
<p>There are at least three important factors that encourage application of
these methods today. First, the availability of flexible, modular
computer languages such as Python. Second, availability of cheap
computational power. Most of all though, an increased awareness of the
benefits of code sharing and reuse is growing in scientific communities.</p>
<section id="philosophy-and-goals">
<h3>Philosophy and goals<a class="headerlink" href="#philosophy-and-goals" title="Permalink to this headline">¶</a></h3>
<blockquote class="epigraph">
<div><p>If it sounds good, it is good.</p>
<p class="attribution">—Duke Ellington</p>
</div></blockquote>
<p>Jazz legend Duke Ellington was talking about music, where it’s all about
the sound. For this package, it’s all about being useful, so we have adopted
a “runs good” philosophy:</p>
<ul class="simple">
<li><p>If it’s a struggle to use, it can’t run good.</p></li>
<li><p>If technical jargon is a barrier, it can’t run good</p></li>
<li><p>If the user finds it useful, it runs good.</p></li>
<li><p>If it runs good, it is good.</p></li>
</ul>
<p>The goals are
modest: to adapt some of the developments in optimal Bayeseian
experimental design research for practical use in laboratory settings,
giving users tools to make better measurements.</p>
</section>
<section id="requirements-for-users">
<h3>Requirements for users<a class="headerlink" href="#requirements-for-users" title="Permalink to this headline">¶</a></h3>
<p>It takes a little effort to get this software up and running. Here’s
what a user will need to supply to get started.</p>
<ol class="arabic simple">
<li><p>Python 3.x with the <code class="docutils literal notranslate"><span class="pre">numpy</span></code> python package</p></li>
<li><p>An experiment that yields measurement results with uncertainty
estimates.</p></li>
<li><p>A reliable parametric model for the experiment, typically a function with
parameters to be determined.</p></li>
<li><p>A working knowledge of Python programming, enough to follow examples
and program a model function.</p></li>
</ol>
</section>
</section>
<section id="theory-of-operation">
<h2>Theory of operation<a class="headerlink" href="#theory-of-operation" title="Permalink to this headline">¶</a></h2>
<p>The optimal Bayes experimental design method incorporates two main jobs,
which we can describe as “learning early” and “making good decisions”</p>
<section id="learning-early">
<h3>Learning early<a class="headerlink" href="#learning-early" title="Permalink to this headline">¶</a></h3>
<p>By interpreting measurement data as soon as it becomes available, sequential Bayesian
experimental design gains a critical advantage over the traditional measure-then-fit design.
With a measure-then-fit strategy, we get information about parameters only at the very end of the
process, after all the measurements and fitting are done. In contrast, the optimal Bayesian
experimental design method updates our parameter knowledge with each measurement result, so
that information-based decisions can be made as data is collected.</p>
<p>The process of digesting new data is Bayesian inference, which frames
parameter knowledge in terms of a probability distribution <span class="math notranslate nohighlight">\(p(\theta)\)</span> for an array of
parameters <span class="math notranslate nohighlight">\(\theta = [ \theta_0, \theta_1, ...]\)</span>. The familiar notation <span class="math notranslate nohighlight">\(a\pm \sigma\)</span>
is often a shorthand description of a Gaussian probability distribution. A broad distribution
<span class="math notranslate nohighlight">\(p(\theta)\)</span> corresponds to large uncertainty, and if <span class="math notranslate nohighlight">\(p(\theta)\)</span> is a narrow
distribution, the uncertainty is small.</p>
<p>When new measurement results <span class="math notranslate nohighlight">\(m\)</span> are taken in to account, there will be a new,
revised probability distribution <span class="math notranslate nohighlight">\(p(\theta|m)\)</span>. The vertical bar in the notation
<span class="math notranslate nohighlight">\(p(\theta|m)\)</span> indicates a conditional probability, so <span class="math notranslate nohighlight">\(p(\theta|m)\)</span> is the
distribution of <span class="math notranslate nohighlight">\(\theta\)</span> values <em>given</em> <span class="math notranslate nohighlight">\(m\)</span>.</p>
<p>Bayes’ rule provides</p>
<div class="math notranslate nohighlight">
\[p(\theta|m) = \frac{p(m|\theta) p(\theta)}{p(m)}.\]</div>
<p>All of the terms here have technical names. The left side is the
<em>posterior</em> distribution, i.e. the distribution of parameters
<span class="math notranslate nohighlight">\(\theta\)</span> after we include <span class="math notranslate nohighlight">\(m\)</span>. On the right, distribution
<span class="math notranslate nohighlight">\(p(\theta)\)</span> is the <em>prior</em>, representing what we knew about the
parameters <span class="math notranslate nohighlight">\(\theta\)</span> before the measurement. In the denominator,
<span class="math notranslate nohighlight">\(p(m)\)</span> is called the <em>evidence</em>, but because it has no <span class="math notranslate nohighlight">\(\theta\)</span>
dependence, it functions just a normalizing constant in this situation.
As wrong as this sounds, we will ignore the <em>evidence</em>.</p>
<p>The term that requires attention is in the numerator; <span class="math notranslate nohighlight">\(p(m|\theta)\)</span> is called the
<em>likelihood</em>. It’s the probability of getting measurement <span class="math notranslate nohighlight">\(m\)</span>
given variable parameter values <span class="math notranslate nohighlight">\(\theta\)</span>.  Less formally, the <em>likelihood</em> answers the
question: “How well does the model explain the measured value
<span class="math notranslate nohighlight">\(m\)</span>, when the model uses different parameter values <span class="math notranslate nohighlight">\(\theta\)</span>?”</p>
<p>In practice, <span class="math notranslate nohighlight">\(m_i\)</span> will be a fixed measurement result to “plug in” for <span class="math notranslate nohighlight">\(m\)</span>. It’s
important to keep sight of the fact that <span class="math notranslate nohighlight">\(p(m_i|\theta)\)</span> is still a function of
theta. Conceptually, we can try out different parameter values in our
model to produce a variety of measurement predictions. Some parameter
values (the more likely ones) will produce model values closer to
<span class="math notranslate nohighlight">\(m_i\)</span> and for other parameters, (the less likely ones), model
model value will be further away.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">optbayesexpt.OptBayesExpt</span></code> class requires the user to report a measurement record
<span class="math notranslate nohighlight">\(m_i\)</span> that includes the measurement settings <span class="math notranslate nohighlight">\(x_i\)</span>, the “value” <span class="math notranslate nohighlight">\(y_i\)</span>, and
uncertainty <span class="math notranslate nohighlight">\(\sigma_i\)</span>. Together, <span class="math notranslate nohighlight">\(y_i\)</span> and <span class="math notranslate nohighlight">\(\sigma_i\)</span> are more than fixed
numbers; they
are shorthand for a probability that a noise-free measurement would yield a value <span class="math notranslate nohighlight">\(y\)</span>.
<span class="math notranslate nohighlight">\(y\)</span> given a mean value <span class="math notranslate nohighlight">\(y_i\)</span>. If this distribution is symmetric, like a Gaussian, for
example, then <span class="math notranslate nohighlight">\(p(y|y_i, \sigma_i) = p(y_i|y, \sigma_i)\)</span>, the probability of measuring
<span class="math notranslate nohighlight">\(y_i\)</span> given a mean value <span class="math notranslate nohighlight">\(y\)</span> that’s provided by the experimental model <span class="math notranslate nohighlight">\(y=y
(x_i,\theta)\)</span>.</p>
<div class="math notranslate nohighlight">
\[p(m_i|\theta) = \frac{1}{\sqrt{2\pi}\sigma_i}
\exp\left[-\frac{[y_i - y(x_i, \theta)]^2 }{ 2\sigma_i^2 } \right].\]</div>
<p>With this <em>likelihood</em>, Bayes theorem provides the updated  <span class="math notranslate nohighlight">\(p(\theta|m_i)\)</span>.
Then, another measurement <span class="math notranslate nohighlight">\(m_j\)</span> can update <span class="math notranslate nohighlight">\(p(\theta|m_i)\)</span> to
<span class="math notranslate nohighlight">\(p(\theta|m_j, m_i, \ldots)\)</span> and so on. In order to keep the
notation readable, we’ll adopt a convention that <span class="math notranslate nohighlight">\(p(\theta)\)</span>
always represents the most up-to-date parameter distribution that we
have.</p>
<p>This approach assumes that our model function <span class="math notranslate nohighlight">\(y(x, \theta)\)</span> is a good description of our
system, and that the measurement noise is Gaussian with standard deviation
<span class="math notranslate nohighlight">\(\sigma_i\)</span>. On one hand we have to admit that these assumptions don’t allow us to
address all important cases. On the other hand, these are the same
assumptions we often make in doing least-squares curve fitting.</p>
<p>The method described above puts the responsibility for determining
measurement uncertainty on the measurement reporter, but as an experimental result, uncertainty is
generally a measurement output, not an input.  If uncertainty is a parameter to be determined, it
enters the process through the likelihood function given above, but it is not part of the model
function <span class="math notranslate nohighlight">\(y(x_i, \theta)\)</span>. See <code class="docutils literal notranslate"><span class="pre">demos/line_plus_noise.py</span></code> for an example.</p>
</section>
<section id="making-good-decisions">
<h3>Making good decisions<a class="headerlink" href="#making-good-decisions" title="Permalink to this headline">¶</a></h3>
<p>The next important job in the process is figuring out good measurement
settings. The goal is to make the parameter probability distribution
<span class="math notranslate nohighlight">\(p(\theta)\)</span> narrow while minimizing cost. More formally, the
challenge is to develop a <em>utility function</em> <span class="math notranslate nohighlight">\(U(x)\)</span> that helps us
to predict and compare the relative benefits of measurements made with
different possible experimental settings <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>Qualitatively, the mechanism for choosing measurement values hinges on the model’s connection
between parameter values <span class="math notranslate nohighlight">\(\theta\)</span> and measurement results <span class="math notranslate nohighlight">\(y\)</span>.
Consider a sampling of several sets of parameter values <span class="math notranslate nohighlight">\(\theta_i\)</span>.  With these parameter
sets, the model can produce a collection of output curves <span class="math notranslate nohighlight">\(y_i(x)\)</span>, and generally these
curves will be closer together for some settings <span class="math notranslate nohighlight">\(x\)</span> and further apart for others.
Intuitively, little would be learned by measuring at <span class="math notranslate nohighlight">\(x\)</span> values where the curves
agree.  Instead, it would do the most good to “pin down” the results with a measurement at an
<span class="math notranslate nohighlight">\(x\)</span> where the predicted <span class="math notranslate nohighlight">\(y_i(x)\)</span> curves disagree.</p>
<p>By drawing samples from the updated parameter distribution <span class="math notranslate nohighlight">\(p(\theta)\)</span> the mechanism above
focuses attention on the relevant parts of parameter space, and through the model to relevant
settings. Or, stated slightly differently, using an updated parameter distribution helps to avoid
wasting measurement resources on low-impact measurements.</p>
<section id="estimate-benefits">
<h4>Estimate benefits<a class="headerlink" href="#estimate-benefits" title="Permalink to this headline">¶</a></h4>
<p>To translate such a qualitative argument into code, “doing the most good”
must be defined more precisely in terms of desired changes in
the parameter distribution <span class="math notranslate nohighlight">\(p(\theta)\)</span>. Usually, the goal in
determining model parameters is to get unambiguous results with small uncertainty. The <em>information
entropy</em> provides a measure of something like a probability distribution. The information entropy
of a probability distribution <span class="math notranslate nohighlight">\(p(a)\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[E = -\int da\; p(a)\; \ln[p(a)].\]</div>
<p>Note that the integrand above is zero for both <span class="math notranslate nohighlight">\(p(a) = 1\)</span> and
<span class="math notranslate nohighlight">\(p(a)=0\)</span>. It’s the intermediate values encountered in a
spread-out distribution where the information entropy accumulates. For
common distributions, like rectangular or Gaussian, that have
characteristic widths <span class="math notranslate nohighlight">\(w\)</span> the entropy goes like <span class="math notranslate nohighlight">\(\ln(w) + C\)</span> with <span class="math notranslate nohighlight">\(C\)</span> values
depending on the shape of the distribution.</p>
<p>Now we can define “doing the most good” in terms of how much
entropy change <span class="math notranslate nohighlight">\(E\)</span>(<em>posterior</em>) - <span class="math notranslate nohighlight">\(E\)</span>(<em>prior</em>) we
might get for predicted measurement values <span class="math notranslate nohighlight">\(y\)</span> at different
settings <span class="math notranslate nohighlight">\(x\)</span>. Actually, we use something slightly
different called the Kulback-Liebler divergence:</p>
<div class="math notranslate nohighlight">
\[D^{KL}(y,x) = \int d\theta\; p(\theta |y,x)
\ln \left[ \frac{p(\theta | y,x)}{p(\theta)}\right].\]</div>
<p>In this expression <span class="math notranslate nohighlight">\(p(\theta | y,x)\)</span> is a speculative parameter
distribution we would get if we happened to measure a value <span class="math notranslate nohighlight">\(y\)</span>
using settings <span class="math notranslate nohighlight">\(x\)</span>. By itself, <span class="math notranslate nohighlight">\(D^{KL}(y,x)\)</span> doesn’t work
as a utility function <span class="math notranslate nohighlight">\(U(x)\)</span> because it depends on this
arbitrary possible measurement value <span class="math notranslate nohighlight">\(y\)</span>. So we need to average
<span class="math notranslate nohighlight">\(D^{KL}\)</span>, weighted by the probability of measuring <span class="math notranslate nohighlight">\(y\)</span>.</p>
<div class="math notranslate nohighlight">
\[U(x) \propto \int dy \int d\theta\; p(y|x) p(\theta |y,x)
\ln \left[ \frac{p(\theta | y,x)}{p(\theta)}\right].\]</div>
<p>With two applications of Bayes rule and some rearrangement this expression for
<span class="math notranslate nohighlight">\(U(x)\)</span> can be rewritten as the difference between two information entropy-like terms:</p>
<dl class="field-list">
<dt class="field-odd">Term 1</dt>
<dd class="field-odd"><p>The information entropy of <span class="math notranslate nohighlight">\(p(y|x)\)</span>, the distribution of
measurement values expected at setting <span class="math notranslate nohighlight">\(x\)</span>. Importantly this distribution
includes likely variations of <span class="math notranslate nohighlight">\(\theta.\)</span> Explicitly,</p>
<div class="math notranslate nohighlight">
\[p(y|x) = \int d\theta'\; p(\theta') p(y|\theta',x)\]</div>
<p>Qualitatively, this term is the information entropy of the predicted measurement values
including both measurement noise and the effects of parameter uncertainty.</p>
</dd>
<dt class="field-even">Term 2</dt>
<dd class="field-even"><p>The other term is the information entropy of <span class="math notranslate nohighlight">\(p(y|\theta,x)\)</span> the measurement value
distribution when <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(x\)</span> are fixed, i.e. the entropy of just the
measurement noise distribution. The entropy of this distribution is averaged over
<span class="math notranslate nohighlight">\(\theta\)</span> values.</p>
<div class="math notranslate nohighlight">
\[\int d\theta\; p(\theta) \int dy\; p(y|\theta,x) \ln [ p(y|\theta, x) ]\]</div>
</dd>
</dl>
<p>Term 1 is the entropy of the <span class="math notranslate nohighlight">\(\theta\)</span>-averaged <span class="math notranslate nohighlight">\(y\)</span>
distribution and Term 2 is the <span class="math notranslate nohighlight">\(\theta\)</span> average of the entropy of
the <span class="math notranslate nohighlight">\(y\)</span> distribution. Loosely, Term 1 is a measure of the spread
in <span class="math notranslate nohighlight">\(y\)</span> values due to both measurement noise and likely parameter
variations, while term 2 is (mostly) just the measurement noise.</p>
<p>An accurate calculation of <span class="math notranslate nohighlight">\(U(x)\)</span> is a big job, requiring integrals over all
parameter space and also all possible measurement outcomes, once for every possible setting.
Fortunately, in keeping with the “runs good” project philosophy, accuracy is not required.
All we require of an approximate utility function is that provides a guide for non-stupid
decisions. It is not critical that the absolute best measurement choice is made
every single time.  It is only necessary to know if there are values of <span class="math notranslate nohighlight">\(x\)</span>
where <span class="math notranslate nohighlight">\(U (x)\)</span> is large compared to other
<span class="math notranslate nohighlight">\(x\)</span>.  Even if we don’t choose the absolute best setting,
a “pretty good” choice will do more good than an uninformed choice.</p>
<p>Consider an approximate calculation of <span class="math notranslate nohighlight">\(U^*(x)\)</span>
where all of the distributions are assumed to be normal (Gaussian). The information
entropy of the normal distribution has a term that goes like
<span class="math notranslate nohighlight">\(\ln\)</span>(width). Term 1 from above is a convolution of the
measurement noise distribution (width = <span class="math notranslate nohighlight">\(\sigma_y\)</span> and the
distribution of model <span class="math notranslate nohighlight">\(y\)</span> values (width =
<span class="math notranslate nohighlight">\(\sigma_{y,\theta}\)</span>) that reflects the connection to the parameter
distribution. A property of normal distributions is that a convolution
of normal distributions is another normal distribution with width =
<span class="math notranslate nohighlight">\(\sqrt{\sigma_{y,\theta}^2 + \sigma_y^2}\)</span>. Under the assumption of
normal distributions, we now have an approximate utility function</p>
<div class="math notranslate nohighlight">
\[U^*(x) \propto \approx \ln(\sqrt{\sigma_\theta^2 + \sigma_y^2}) - \ln(\sigma_y)
        = \frac{1}{2}\ln\left[\frac{\sigma_{y,\theta}(x)^2}{\sigma_y(x)^2}+1\right]\]</div>
<p>This approximation has some reasonable properties. The dependence on
<span class="math notranslate nohighlight">\(\sigma_{y,\theta}\)</span> matches our initial intuition that
high-utility parameters are those where measurements vary a lot due to
parameter variations. The dependence on measurement noise
<span class="math notranslate nohighlight">\(\sigma_y\)</span> also has an intuitive interpretation: that it’s less
useful to make measurements at settings <span class="math notranslate nohighlight">\(x\)</span> where the
instrumental noise is larger. This approximate utility function is
also positive, i.e. more data helps narrow a distribution.</p>
</section>
<section id="estimate-the-costs">
<h4>Estimate the costs<a class="headerlink" href="#estimate-the-costs" title="Permalink to this headline">¶</a></h4>
<p>The utility as described above focuses on the information entropy change,
but if the question is about making efficient measurements, the cost of the
measurements is fully half of the problem.  In the simplest situations, the
time spent measuring is the only cost.  In more “interesting” situations,
there may be a cost associated with changing settings, the cost of a
measurement may depend on the likelihood of damage. So in contrast to the
general approach to predicting information entropy change, the cost closely
associated with local conditions.</p>
</section>
</section>
</section>
<section id="guided-tour">
<h2>Guided Tour<a class="headerlink" href="#guided-tour" title="Permalink to this headline">¶</a></h2>
<p>Where the section above treats the theory of Bayesian experimental design,
this section provides an introduction to the algorithms and methods in the
<code class="docutils literal notranslate"><span class="pre">OptBayesExpt</span></code>
class that perform the “learn fast” and “make good decisions” tasks.
An additional subsection describes how the parameter probability
distribution is implemented.</p>
<section id="learn-fast-routine">
<h3>Learn fast routine<a class="headerlink" href="#learn-fast-routine" title="Permalink to this headline">¶</a></h3>
<aside class="sidebar">
<p class="sidebar-title">Measurement inputs</p>
<a class="reference internal image-reference" href="_images/obe_pdf_update_flowchart.png"><img alt="_images/obe_pdf_update_flowchart.png" src="_images/obe_pdf_update_flowchart.png" style="width: 317.45px; height: 193.89999999999998px;" /></a>
</aside>
<p>To input measurement data, the user script invokes
<code class="docutils literal notranslate"><span class="pre">pdf_update(measurement_result)</span></code>.  The events that follow are illustrated
in the sidebar.  <code class="docutils literal notranslate"><span class="pre">OptBaesExpt</span></code> requires the user to provide a
<code class="docutils literal notranslate"><span class="pre">measurement_result</span></code> that represents a complete measurement record with
the settings, the value and the uncertainty. The settings are required since
actual settings may differ from suggested settings. The settings are used to
evaluate the model function for every parameter sample in the
parameter probability distribution to produce <code class="docutils literal notranslate"><span class="pre">y_model_data</span></code>. For each
parameter sample the difference between the model value and the reported
measurement value is used to calculate the likelihood of that parameter
sample, assuming a Gaussian noise distribution.</p>
<p>The uncertainty deserves some attention. By requiring the measurement
uncertainty, OptBayesExpt places the burden of determining the uncertainty
on the experimenter. Bluntly, the reason for this requirement is that it makes
the programming easier. But often, the noise is one of the things one would
like to learn from an experiment.</p>
<p>To include the raw measurement uncertainty as an unknown, it is
convenient to create a child class that inherits from OptBayesExpt.
<code class="docutils literal notranslate"><span class="pre">ChildClass</span></code> may include the uncertainty alongside the
actual model parameters in the <code class="docutils literal notranslate"><span class="pre">parameter_samples</span></code> tuple, as suggested by
the dashed arrow in the sidebar. In this arrangement, the
uncertainty parameter is not used in the
model function, but it does enter the likelihood calculation.  After all,
some values of uncertainty explain the data better than others. For examples of
this approach, see</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">demos/obe_line_plus_noise.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">demos/obe_lockin.py</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">demos/obe_sweeper.py</span></code></p></li>
</ul>
</div></blockquote>
<p><code class="docutils literal notranslate"><span class="pre">ParticlePdf.bayesian_update()</span></code> adjusts the parameter distribution
(including the uncertainty part) based on the likelihood.</p>
</section>
<section id="make-good-decisions-routine">
<h3>Make good decisions routine<a class="headerlink" href="#make-good-decisions-routine" title="Permalink to this headline">¶</a></h3>
<aside class="sidebar">
<p class="sidebar-title">Setting selection</p>
<a class="reference internal image-reference" href="_images/utility.png"><img alt="_images/utility.png" src="_images/utility.png" style="width: 317.79999999999995px; height: 349.29999999999995px;" /></a>
</aside>
<p>Measurement settings are selected by <code class="docutils literal notranslate"><span class="pre">opt_setting()</span></code> and <code class="docutils literal notranslate"><span class="pre">good_setting</span></code>,
and both of these rely on <code class="docutils literal notranslate"><span class="pre">utility()</span></code>.  The sidebar illustrates the inner
workings of <code class="docutils literal notranslate"><span class="pre">utility()</span></code>, where the most time-consuming part is
<code class="docutils literal notranslate"><span class="pre">yvar_from_parameter_draws()</span></code>.  For each of <code class="docutils literal notranslate"><span class="pre">N_DRAWS</span></code> samples from
the parameter distribution the model function is evaluated for every
possible setting combination, yielding a set of outputs for each setting.  The
variance of these outputs is compared to the model experimental noise which
is a constant by default.  The examples listed above for unknown
uncertainties include the mean of the variance as a model of experimental
noise.</p>
<p>In the deoniminator, the cost of a potential experiment may depend on
settings, or predicted value or distance to the next setting.  There are
many possibilities.  In <code class="docutils literal notranslate"><span class="pre">OptBayesExpt</span></code> the cost is constant by default but
customized cost models can be programmed into child classes.
In <code class="docutils literal notranslate"><span class="pre">demos/obe_lockin.py</span></code> for example, the cost model includes the additional
cost of a settling time if the setting is changed from its current value.  In
<code class="docutils literal notranslate"><span class="pre">demos/obe_sweeper.py</span></code>, the cost model includes a cost of setting up a
sweep plus a cost proportional to the length of the sweep.</p>
<p>Once the utility is computed, <code class="docutils literal notranslate"><span class="pre">opt_setting()</span></code> and <code class="docutils literal notranslate"><span class="pre">good_setting()</span></code>
offer different strategies for selecting settings for the next measurement.
The <code class="docutils literal notranslate"><span class="pre">opt_setting()</span></code> method implements a “greedy” strategy, always
selecting the setting that generates the maximum utility.  The
resulting measurements tend to cluster strongly around a few settings. The
<code class="docutils literal notranslate"><span class="pre">good_setting()</span></code> method uses the utility as a weighting function for a
random setting selection. To tilt the odds toward selecting settings
with higher utility, the contrast between high and low utility is stretched
by raising utility to a power, <code class="docutils literal notranslate"><span class="pre">pickiness</span></code>.  The contrasting behavior of
<code class="docutils literal notranslate"><span class="pre">opt_settting()</span></code> and <code class="docutils literal notranslate"><span class="pre">good_setting()</span></code> with different <code class="docutils literal notranslate"><span class="pre">pickiness</span></code>
values are illustrated by <code class="docutils literal notranslate"><span class="pre">demos/line_plus_noise.py</span></code></p>
</section>
<section id="probability-distribution-class">
<h3>Probability distribution class<a class="headerlink" href="#probability-distribution-class" title="Permalink to this headline">¶</a></h3>
<aside class="sidebar">
<p class="sidebar-title">Probability distributions</p>
<a class="reference internal image-reference" href="_images/particleFilter.png"><img alt="_images/particleFilter.png" src="_images/particleFilter.png" style="width: 320.0px; height: 240.0px;" /></a>
</aside>
<p>The probability distribution over the model parameters is at the core of
<code class="docutils literal notranslate"><span class="pre">OptBayesExpt</span></code>.  As of version 1.0, the optbayesexpt package uses the
<code class="docutils literal notranslate"><span class="pre">particlePDF</span></code> class to implement the distribution function for <em>N</em>
parameters as a cloud or swarm of particles in <em>N</em>-dimensional parameter
space.  This approach has been given several names, but “sequential Monte
Carlo” seems to be gaining traction.  Each point in the cloud has
coordinates corresponding to parameter values, and also a weight, normalized
so that the sum of the weights is 1. The
density of particles in a small region and the weights of those particles
together provide a flexible representation of the probability density.  The
figure in the sidebar illustrates how this works for a 1-D normal (Gaussian)
distribution. Panel (a) plots 100 draws from the normal distribution, each
with a weight of 0.01. The probability distribution is represented only
by the density of points in this case. Panel (b) represents the same normal
distribution using only the weights.  The points are 100 draws from a
<em>uniform</em> distribution, but the weights represent the normal distribution.</p>
<p>In the learning fast stage, the distribution is modified based on new data.
The likelihood is calculated for every point in
the distribution cloud, and then ParticlePdf.bayesian_update() multiplies
the particle’s weight by its likelihood.  So the distribution is easily
modified by adjusting weight values.</p>
<p>In the decision making stage, random draws of parameters from the
probability distribution are used to calculate utility.  Draws are made by
random selection of points with probability determined by weights.  In panel
(a) values at the center are more likely to be chosen because the density is
higher there.  In panel (b), values at the center are more likely to be
chosen because the weights are higher there.</p>
<p><code class="docutils literal notranslate"><span class="pre">ParticlePdf</span></code> also performs a self-maintenance function, <code class="docutils literal notranslate"><span class="pre">resample()</span></code>.
As the incoming data is used to modify the
distribution, some regions of parameter space may develop very low
probabilities. The points near the ends of the plot in panel (b) illustrate
the issue. These low-weight points will almost never be chosen in
random draws, but they consume computational resources.  In resampling, <em>N</em>
draws are taken from an <em>N</em>-particle distribution, so some high-weight
particles will be chosen more than once and low-weight particles may not be
chosen at all. Each particle is then given a small random nudge to separate
copies of the same original particle, the cloud of points is shrunk
slightly to compensate for the one-step diffusion, and the weight is divided
evenly between particles as shown in panel (c). Resampling relocates
low-weight particles to higher-weight neighborhoods so that as measurements
narrow the distributions of parameter values, the representation adapts.</p>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Manual</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a><ul>
<li><a class="reference internal" href="#philosophy-and-goals">Philosophy and goals</a></li>
<li><a class="reference internal" href="#requirements-for-users">Requirements for users</a></li>
</ul>
</li>
<li><a class="reference internal" href="#theory-of-operation">Theory of operation</a><ul>
<li><a class="reference internal" href="#learning-early">Learning early</a></li>
<li><a class="reference internal" href="#making-good-decisions">Making good decisions</a><ul>
<li><a class="reference internal" href="#estimate-benefits">Estimate benefits</a></li>
<li><a class="reference internal" href="#estimate-the-costs">Estimate the costs</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#guided-tour">Guided Tour</a><ul>
<li><a class="reference internal" href="#learn-fast-routine">Learn fast routine</a></li>
<li><a class="reference internal" href="#make-good-decisions-routine">Make good decisions routine</a></li>
<li><a class="reference internal" href="#probability-distribution-class">Probability distribution class</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="quickstart.html"
                        title="previous chapter">Quick Start</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="manual_demos.html"
                        title="next chapter">Demos</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/manual.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="manual_demos.html" title="Demos"
             >next</a> |</li>
        <li class="right" >
          <a href="quickstart.html" title="Quick Start"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">OptBayesExpt 1.1.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Manual</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright National Institute of Standards and Technology.Not subject to copyright in the United States..
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.0.2.
    </div>
  </body>
</html>