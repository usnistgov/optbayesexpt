
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>optbayesexpt.obe_base &#8212; OptBayesExpt 1.0.0 documentation</title>
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css" type="text/css" />
    <script src="https://code.jquery.com/jquery-1.12.4.min.js" type="text/javascript"></script>
    <script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript" defer="defer"></script>

<script type="text/javascript" src="https://pages.nist.gov/leaveNotice/js/jquery.leaveNotice-nist.min.js"></script>
<script>
$(document).ready(function(){
  // Mark external (non-nist.gov) A tags with class "external"
  //If the adress start with https and ends with nist.gov
  var re_nist = new RegExp('^https?:\/\/((^\/)*\.)*nist\\.gov(\/|$)');
  //Regex to find address that start with https
  var re_absolute_address = new RegExp('^((https?:)?\/\/)');
  $("a").each(function(){
    var url=$(this).attr('href');
    if(re_nist.test(url) || !re_absolute_address.test(url)){
      $(this).addClass('local');
    }else{
      //This a href appears to be external, so tag it
      $(this).addClass('external');
    }
  });
  // Add leaveNotice to external A elements
  $('a.external').leaveNotice();
});
</script>
<link rel="stylesheet" type="text/css" href="https://pages.nist.gov/leaveNotice/css/jquery.leaveNotice.css" />

<script async type="text/javascript" id="_fed_an_ua_tag" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=NIST&subagency=github&pua=UA-42404149-54&yt=true&exts=ppsx,pps,f90,sch,rtf,wrl,txz,m1v,xlsm,msi,xsd,f,tif,eps,mpg,xml,pl,xlt,c">
</script>

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OptBayesExpt 1.0.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for optbayesexpt.obe_base</h1><div class="highlight"><pre>
<span></span><span class="n">__author__</span> <span class="o">=</span> <span class="s1">&#39;Bob McMichael&#39;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">.particlepdf</span> <span class="kn">import</span> <span class="n">ParticlePDF</span>


<div class="viewcode-block" id="OptBayesExpt"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt">[docs]</a><span class="k">class</span> <span class="nc">OptBayesExpt</span><span class="p">(</span><span class="n">ParticlePDF</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;An implementation of sequential Bayesian experimental design.</span>

<span class="sd">    OptBayesExpt is a manager that calculates strategies for efficient</span>
<span class="sd">    measurement runs. OptBayesExpt incorporates measurement data, and uses</span>
<span class="sd">    that information to select settings for measurements with high</span>
<span class="sd">    predicted benefit / cost ratios.</span>

<span class="sd">    The use cases are situations where the goal is to find the parameters of</span>
<span class="sd">    a parametric model.</span>

<span class="sd">    The primary functions of this class are to interpret measurement data</span>
<span class="sd">    and to calculate effective settings. The corresponding methods that</span>
<span class="sd">    perform these functions are ``OptBayesExpt.update_pdf()`` for</span>
<span class="sd">    interpretation of new data and either ``OptBayesExpt.opt_setting()`` or</span>
<span class="sd">    ``OptBayesExpt.good_setting()`` for calculation of effective settings.</span>

<span class="sd">    Instances of OptBayesExpt itself may be used for cases where</span>

<span class="sd">    #. Reported measurement data includes measurement uncertainty,</span>
<span class="sd">    #. Every measurement is assumed to cost the same amount.</span>
<span class="sd">    #. The measurement noise is assumed to be constant</span>

<span class="sd">    OptBayesExpt may be inherited by child classes to allow additional</span>
<span class="sd">    flexibility.  Examples in the ``demos`` folder show several extensions</span>
<span class="sd">    including unknown noise, and setting-dependent costs.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_function (:obj:`function`): Evaluates the experimental model</span>
<span class="sd">            from (:code:`settings`, :code:`parameters`, :code:`constants`)</span>
<span class="sd">            arguments, returning single values or arrays depending on the</span>
<span class="sd">            arguments.  The :code:`model_function` is very similar to the</span>
<span class="sd">            fit function in a least-squares regression. The</span>
<span class="sd">            :code:`model_function()` must allow evaluation in both of the</span>
<span class="sd">            following forms:</span>

<span class="sd">            - :code:`model_function(tuple_of_single_settings,</span>
<span class="sd">              tuple_of_parameter_arrays, tuple_of_constants)`, returning an</span>
<span class="sd">              array with the same size as one of the parameter arrays.</span>
<span class="sd">            - :code:`model_function(tuple_of_setting_arrays,</span>
<span class="sd">              tuple_of_single_parameters, tuple_of_constants)`, returning</span>
<span class="sd">              an array with the same size as one of the setting arrays.</span>

<span class="sd">            The broadcasting feature of numpy arrays provides a convenient</span>
<span class="sd">            way to write this type of function for simple analytical models.</span>

<span class="sd">        setting_values (:obj:`tuple` of :obj:`ndarray`):</span>
<span class="sd">            Each array in the :code:`setting_values` tuple contains the</span>
<span class="sd">            allowed discrete values of a measurement setting.  Applied</span>
<span class="sd">            voltage, excitation frequency, and a knob that goes to eleven</span>
<span class="sd">            are all examples of settings. For computational speed,</span>
<span class="sd">            it is important to keep setting arrays appropriately sized.</span>
<span class="sd">            Settings arrays that cover unused setting values, or that use</span>
<span class="sd">            overly fine discretization will slow the calculations. Settings</span>
<span class="sd">            that are held constant belong in the :code:`constants` array.</span>

<span class="sd">        parameter_samples (:obj:`tuple` of :obj:`ndarray`):</span>
<span class="sd">            Each array in the :code:`parameter_samples` tuple contains the</span>
<span class="sd">            possible values of a model parameter.  In a simple example</span>
<span class="sd">            model, :code:`y = m * x + b`, the parameters are :code:`m` and</span>
<span class="sd">            :code:`b`.  As with the :code:`setting_values`,</span>
<span class="sd">            :code:`parameter_samples` arrays should be kept few and small.</span>
<span class="sd">            Parameters that can be assumed constant belong in the</span>
<span class="sd">            :code:`constants` array. Discretization should only be fine</span>
<span class="sd">            enough to support the needed measurement precision. The</span>
<span class="sd">            parameter ranges must also be limited: too broad, and the</span>
<span class="sd">            computation will be slow; too narrow, and the measurement may</span>
<span class="sd">            have to be adjusted and repeated.</span>

<span class="sd">        constants (:obj:`tuple` of :obj:`float`):</span>
<span class="sd">            Model constants.  Examples include experimental settings that</span>
<span class="sd">            are rarely changed, and model parameters that are well-known</span>
<span class="sd">            from previous measurement results.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        model_function (:obj:`function`): Same as the ``model_function``</span>
<span class="sd">            parameter above.</span>

<span class="sd">        setting_values (:obj:`tuple` of :obj:`ndarray`): A record of the</span>
<span class="sd">            setting_values argument.</span>

<span class="sd">        allsettings (:obj:`list` of :obj:`ndarray`): Arrays containing all</span>
<span class="sd">            possible combinations of the setting values provided in the</span>
<span class="sd">            ``setting_values`` argument.</span>

<span class="sd">        setting_indices (:obj:`ndarray` of :obj:`int`): indices in to</span>
<span class="sd">            the allsettings arrays. Used in ``opt_setting()`` and</span>
<span class="sd">            ``good_setting()``.</span>

<span class="sd">        parameters (:obj:`ndarray` of :obj:`ndarray`): The most recently</span>
<span class="sd">            set of parameter samples the parameter distribution.</span>
<span class="sd">            ``self.parameters`` is a *view* of ``PartcilePDF.particles``.</span>

<span class="sd">        cons (:obj:`tuple` of :obj:`float`): Stores the ``constants``</span>
<span class="sd">            argument tuple.</span>

<span class="sd">        default_noise_std (:obj:`float`): A rough-estimate of measurement</span>
<span class="sd">            noise as a standard-deviation. The default return value of</span>
<span class="sd">            ``cost()``.</span>

<span class="sd">        measurement_results (:obj:`list`): A list containing records of</span>
<span class="sd">            accumulated measurement results</span>

<span class="sd">        last_setting_index (:obj:`int`): The most recent settings</span>
<span class="sd">            recommendation as an index into ``self.allsettings``.</span>

<span class="sd">        N_DRAWS (int): The number of parameter draws to use in the utility</span>
<span class="sd">            calculation to estimate the variance of model outputs due to</span>
<span class="sd">            parameter distribution.  Default: 30</span>
<span class="sd">   &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model_function</span><span class="p">,</span> <span class="n">setting_values</span><span class="p">,</span> <span class="n">parameter_samples</span><span class="p">,</span>
                 <span class="n">constants</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model_function</span> <span class="o">=</span> <span class="n">model_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setting_values</span> <span class="o">=</span> <span class="n">setting_values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allsettings</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">setting_values</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">setting_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">allsettings</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">ParticlePDF</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameter_samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cons</span> <span class="o">=</span> <span class="n">constants</span>

        <span class="c1"># A noise level estimate used in setting selection</span>
        <span class="c1"># used by ``y_var_noise_model()``.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_noise_std</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="c1"># A list containing records of accumulated measurement results</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">measurement_results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Indices of most recent requested setting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_setting_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># The number of parameter draws to use in the utility calculation.</span>
        <span class="c1"># Default: 30</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_DRAWS</span> <span class="o">=</span> <span class="mi">30</span>

<div class="viewcode-block" id="OptBayesExpt.eval_over_all_parameters"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.eval_over_all_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">eval_over_all_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">onesettingset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluates the experimental model.</span>

<span class="sd">        Evaluates the model for one combination of measurement settings and</span>
<span class="sd">        all parameter combinations in ``self.parameters``. Called by</span>
<span class="sd">        ``pdf_update()`` for ``likelihood()`` and Bayesian inference</span>
<span class="sd">        processing of measurement results.</span>

<span class="sd">        This method and ``eval_over_all_settings()`` both call</span>
<span class="sd">        ``model_function()``, but with different argument types.  If the</span>
<span class="sd">        broadcasting properties of numpy arrays are not able to resolve this</span>
<span class="sd">        polymorphism, this method may be replaced by a separate method for</span>
<span class="sd">        model evaluation.</span>

<span class="sd">        Args:</span>
<span class="sd">            onesettingset (:obj:`tuple` of :obj:`float`): a single set of</span>
<span class="sd">                measurement settings</span>

<span class="sd">        Returns:</span>
<span class="sd">            (:obj:`ndarray`) array of model values with dimensions of one</span>
<span class="sd">            element of :obj:`self.allparams`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_function</span><span class="p">(</span><span class="n">onesettingset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cons</span><span class="p">)</span></div>

<div class="viewcode-block" id="OptBayesExpt.eval_over_all_settings"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.eval_over_all_settings">[docs]</a>    <span class="k">def</span> <span class="nf">eval_over_all_settings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">oneparamset</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Evaluates the experimental model.</span>

<span class="sd">        Evaluates the model for all combinations of measurement settings in</span>
<span class="sd">        ``self.allsettings`` and one set of parameters. Called ``N_DRAWS``</span>
<span class="sd">        times by ``yvar_from_parameter_draws()`` as part of the ``utility()``</span>
<span class="sd">        calculation</span>

<span class="sd">        Args:</span>
<span class="sd">            oneparamset (:obj:`tuple` of :obj:`float`): a single set of</span>
<span class="sd">                model parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (:obj:`ndarray`) array of model values with dimensions of one</span>
<span class="sd">            element of :code:`self.allsettings`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">allsettings</span><span class="p">,</span> <span class="n">oneparamset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cons</span><span class="p">)</span></div>

<div class="viewcode-block" id="OptBayesExpt.pdf_update"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.pdf_update">[docs]</a>    <span class="k">def</span> <span class="nf">pdf_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">measurement_record</span><span class="p">,</span> <span class="n">y_model_data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Refines the parameters&#39; probability distribution function given a</span>
<span class="sd">        measurement result.</span>

<span class="sd">        This is the measurement result input method. An implementation of</span>
<span class="sd">        Bayesian inference, uses the model to calculate the ikelihood of</span>
<span class="sd">        obtaining the measurement result :code:`ymeas` as a function of</span>
<span class="sd">        parameter values, and uses that likelihood to generate a refined</span>
<span class="sd">        *posterior* ( after-measurement) distribution from the *prior* (</span>
<span class="sd">        pre-measurement) distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            measurement_record (:obj:`tuple`): A record of the measurement</span>
<span class="sd">                containing at least the settings and the measured value(s).</span>
<span class="sd">                The first element of ``measurement_record`` gets passed as a</span>
<span class="sd">                settings tuple to ``evaluate_over_all_parameters()`` The</span>
<span class="sd">                entire ``measurement_result`` tuple gets forwarded to</span>
<span class="sd">                ``likelihood()``.</span>

<span class="sd">            y_model_data (:obj:`ndarray`): The result of</span>
<span class="sd">                :code:`self.eval_over_all_parameters()` This argument allows</span>
<span class="sd">                model evaluation to run before measurement data is</span>
<span class="sd">                available, e.g. while measurements are being made. Default =</span>
<span class="sd">                ``None``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># unpack the measurement result</span>
        <span class="n">onesetting</span> <span class="o">=</span> <span class="n">measurement_record</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># calculate the model for all values of the parameters</span>
        <span class="k">if</span> <span class="n">y_model_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y_model_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_over_all_parameters</span><span class="p">(</span><span class="n">onesetting</span><span class="p">)</span>

        <span class="c1"># Calculate the *likelihood* of measuring `measurmennt_result` for</span>
        <span class="c1"># all parameter combinations</span>
        <span class="n">likyhd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span><span class="p">(</span><span class="n">y_model_data</span><span class="p">,</span> <span class="n">measurement_record</span><span class="p">)</span>

        <span class="c1"># update the pdf using a method inherited from ParticlePDF()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bayesian_update</span><span class="p">(</span><span class="n">likyhd</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">particles</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">just_resampled</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enforce_parameter_constraints</span><span class="p">()</span></div>

<div class="viewcode-block" id="OptBayesExpt.enforce_parameter_constraints"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.enforce_parameter_constraints">[docs]</a>    <span class="k">def</span> <span class="nf">enforce_parameter_constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Enforces constraints on parameters</span>

<span class="sd">        for example::</span>

<span class="sd">            # find the violators (negative parameter values)</span>
<span class="sd">            bad_ones = np.argwhere(self.parameters[3] &lt; 0)</span>
<span class="sd">                for index in bad_ones:</span>
<span class="sd">                    self.particle_weights[index] = 0</span>
<span class="sd">            # renormalize</span>
<span class="sd">            self.particle_weights = self.particle_weights \</span>
<span class="sd">                / np.sum(self.particle_weights)</span>

<span class="sd">        Returns:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="OptBayesExpt.likelihood"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_model</span><span class="p">,</span> <span class="n">measurement_record</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the likelihood of a measurement result.</span>

<span class="sd">        For each parameter combination, estimate the probability of</span>
<span class="sd">        obtaining the results provided in :code:`measurement_result`.  This</span>
<span class="sd">        default method relies on several assumptions:</span>

<span class="sd">        - A single measurement yields a single value :math:`y_{meas}`</span>
<span class="sd">        - The uncertainty in that value is well-described by additive</span>
<span class="sd">          Gaussian noise.</span>
<span class="sd">        - The the standard deviation of the noise, :math:`\sigma` is known.</span>

<span class="sd">        Under these assumptions, and model values :math:`y_{model}` as a</span>
<span class="sd">        function of parameters, the likelihood is a Gaussian function</span>
<span class="sd">        proportional to :math:`\sigma^{-1} \exp [(y_{model} - y_{meas})^2</span>
<span class="sd">        / (2 \sigma^2)]`.</span>

<span class="sd">        Args:</span>
<span class="sd">            y_model (:obj:`ndarray`): ``model_function()`` results evaluated</span>
<span class="sd">                for all parameters.</span>
<span class="sd">            measurement_record (:obj:`tuple`): The measurement conditions</span>
<span class="sd">                and results, supplied by the user to ``update_pdf()``. The</span>
<span class="sd">                elements of ``measurement_record`` are:</span>

<span class="sd">                    - settings (tuple)</span>
<span class="sd">                    - measurement value (float)</span>
<span class="sd">                    - std uncertainty (float)</span>

<span class="sd">        Returns:</span>
<span class="sd">            an array of probabilities corresponding to the parameters in</span>
<span class="sd">            :code:`self.allparameters`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># unpack the measurement_record</span>
        <span class="n">onesetting</span><span class="p">,</span> <span class="n">y_meas</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">measurement_record</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">y_model</span> <span class="o">-</span> <span class="n">y_meas</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span></div>

<div class="viewcode-block" id="OptBayesExpt.yvar_from_parameter_draws"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.yvar_from_parameter_draws">[docs]</a>    <span class="k">def</span> <span class="nf">yvar_from_parameter_draws</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Models the measurement variance solely due to parameter</span>
<span class="sd">        distributions.</span>

<span class="sd">        Evaluates the effect ov the distribution</span>
<span class="sd">        of parameter values on the distribution of model outputs for every</span>
<span class="sd">        setting combination. This calculation is done as part of the</span>
<span class="sd">        *utility* calculation as an approximation to the information</span>
<span class="sd">        entropy. For each of ``self.N_DRAWS`` samples from the parameter</span>
<span class="sd">        distribution, this method models a noise-free experimental output</span>
<span class="sd">        for all setting combinations and returns the variance of the model</span>
<span class="sd">        values for each setting combination.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`ndarray` with shape of a member of all_settings</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">paramsets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">randdraw</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_DRAWS</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="c1"># make space for model results</span>
        <span class="n">ycalc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">N_DRAWS</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">allsettings</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># the default for the default number of draws is set in __init__()</span>

        <span class="c1"># fill the model results for each drawn parameter set</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">oneparamset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">paramsets</span><span class="p">):</span>
            <span class="n">ycalc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_over_all_settings</span><span class="p">(</span><span class="n">oneparamset</span><span class="p">)</span>

        <span class="c1"># Evaluate how much the model varies at each setting</span>
        <span class="c1"># calculate the variance of results for each setting</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">ycalc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="OptBayesExpt.y_var_noise_model"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.y_var_noise_model">[docs]</a>    <span class="k">def</span> <span class="nf">y_var_noise_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Models the measurement variance solely due to measurement noise.</span>

<span class="sd">        A model of measurement variance (noise) as a function of settings,</span>
<span class="sd">        averaged over parameters if parameter-dependent.  Used in the</span>
<span class="sd">        *utility* calculation.</span>

<span class="sd">        In general, the measurement noise could depend on both settings and</span>
<span class="sd">        parameters, and the model would require evaluation of the noise</span>
<span class="sd">        model over all parameters, averaged over draws from the parameter</span>
<span class="sd">        distribution.  Measurement noise that depends on the measurement</span>
<span class="sd">        value, like root(N), Poisson-like counting noise is an example of</span>
<span class="sd">        such a situation. Fortunately, this noise estimate only affects the</span>
<span class="sd">        utility function, which only affects setting choices, where the</span>
<span class="sd">        &quot;runs good&quot; philosophy of the project allows a little approximation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            If measurement noise is independent of settings, a :obj:`float`,</span>
<span class="sd">            otherwise an :obj:`ndarray` with the shape of an</span>
<span class="sd">            element of `allsettings`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_noise_std</span> <span class="o">**</span> <span class="mi">2</span></div>

<div class="viewcode-block" id="OptBayesExpt.cost_estimate"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.cost_estimate">[docs]</a>    <span class="k">def</span> <span class="nf">cost_estimate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the cost of measurements, depending on settings</span>

<span class="sd">        The denominator of the *utility* function allows measurement</span>
<span class="sd">        resources (e.g. setup time + data collection time) to be entered</span>
<span class="sd">        into the utility calculation.</span>

<span class="sd">        Returns:</span>
<span class="sd">            :obj:`float`, otherwise an :obj:`ndarray` describing how</span>
<span class="sd">                measurement variance depends on settings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">1.0</span></div>

<div class="viewcode-block" id="OptBayesExpt.utility"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.utility">[docs]</a>    <span class="k">def</span> <span class="nf">utility</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Estimate the utility as a function of settings.</span>

<span class="sd">        Used in selecting measurement settings. The *utility* is the</span>
<span class="sd">        predicted benefit/cost ratio of a new measurement where the benefit</span>
<span class="sd">        is given in terms of a change in the information entropy of the</span>
<span class="sd">        parameter distribution.  Here we use an approximation that assumes</span>
<span class="sd">        Gaussian distributions.</span>

<span class="sd">        Returns:</span>
<span class="sd">            utility as an :obj:`ndarray` with dimensions of a member of</span>
<span class="sd">            :code:`allsettings`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">var_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">yvar_from_parameter_draws</span><span class="p">()</span>
        <span class="n">var_n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_var_noise_model</span><span class="p">()</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_estimate</span><span class="p">()</span>

        <span class="n">utility</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">var_p</span> <span class="o">/</span> <span class="n">var_n</span><span class="p">)</span> <span class="o">/</span> <span class="n">cost</span>

        <span class="k">return</span> <span class="n">utility</span></div>

<div class="viewcode-block" id="OptBayesExpt.opt_setting"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.opt_setting">[docs]</a>    <span class="k">def</span> <span class="nf">opt_setting</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Find the setting with maximum predicted impact on the parameter</span>
<span class="sd">        distribution.</span>

<span class="sd">        At what settings are we most uncertain about how an experiment will</span>
<span class="sd">        come out? That is where the next measurement will do the most good.</span>
<span class="sd">        So, we calculate model outputs for a bunch of possible model</span>
<span class="sd">        parameters and see wherethe output varies the most. We use our</span>
<span class="sd">        accumulated knowledge by drawing the possible parameters from the</span>
<span class="sd">        current parameter pdf.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A settings tuple.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">utility</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">utility</span><span class="p">()</span>

        <span class="c1"># Find the settings with the maximum utility</span>
        <span class="c1"># argmax returns an array of indices into the flattened array</span>
        <span class="n">bestindex</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">utility</span><span class="p">)</span>

        <span class="c1"># translate to setting values</span>
        <span class="c1"># allsettings is a list of setting arrays generated by np.meshgrid,</span>
        <span class="c1"># one for each &#39;knob&#39;</span>
        <span class="n">bestvalues</span> <span class="o">=</span> <span class="p">[</span><span class="nb">set</span><span class="p">[</span><span class="n">bestindex</span><span class="p">]</span> <span class="k">for</span> <span class="nb">set</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">allsettings</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_setting_index</span> <span class="o">=</span> <span class="n">bestindex</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">bestvalues</span><span class="p">)</span></div>

<div class="viewcode-block" id="OptBayesExpt.good_setting"><a class="viewcode-back" href="../../optbayesexpt.html#optbayesexpt.obe_base.OptBayesExpt.good_setting">[docs]</a>    <span class="k">def</span> <span class="nf">good_setting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pickiness</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate a setting with a good probability of refining the pdf</span>

<span class="sd">        ``good_setting()`` selects settings using a weighted random</span>
<span class="sd">        selection using the utility function to calculate a weight.  The</span>
<span class="sd">        weight function is ``utility( )`` raised to the ``pickiness`` power.</span>
<span class="sd">        In comparison to the ``opt_setting()`` method, where the</span>
<span class="sd">        measurements select only the very best setting, ``good_setting()``</span>
<span class="sd">        yields a more diverse series of settings.</span>

<span class="sd">        Args:</span>
<span class="sd">            pickiness (float): A setting selection tuning parameter.</span>
<span class="sd">                Pickiness=0 produces random settingss.  With pickiness</span>
<span class="sd">                values greater than about 10 the behavior is similar to</span>
<span class="sd">                :code:`opt_setting()`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A settings tuple.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">utility</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">utility</span><span class="p">())</span> <span class="o">**</span> <span class="n">pickiness</span>
        <span class="c1"># the exponent &#39;pickiness&#39; is a tuning parameter</span>

        <span class="n">utility</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">utility</span><span class="p">)</span>
        <span class="n">goodindex</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">setting_indices</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">utility</span><span class="p">)</span>
        <span class="n">goodvalues</span> <span class="o">=</span> <span class="p">[</span><span class="nb">set</span><span class="p">[</span><span class="n">goodindex</span><span class="p">]</span> <span class="k">for</span> <span class="nb">set</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">allsettings</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_setting_index</span> <span class="o">=</span> <span class="n">goodindex</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">goodvalues</span><span class="p">)</span></div></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">OptBayesExpt 1.0.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright National Institute of Standards and Technology.Not subject to copyright in the United States..
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.4.4.
    </div>
  </body>
</html>